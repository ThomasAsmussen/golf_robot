training:
  episodes: 1000
  actor_lr: 0.001
  critic_lr: 0.002 # #at 215 steps before 0.0008
  noise_std: 0.0
  batch_size: 128
  grad_steps: 2
  replay_buffer_capacity: 100000
  use_wandb: True
  project_name: "real_fewer_neurons_sim"
  eval_interval: 50
  eval_episodes: 30
  target_update_rho: 0.000
  continue_training: False
  error_hard_stop: True
  do_prints: False
  env_type: "sim"
  # model_name: None
  wandb_run_id: "real_robot_11_02_2026_10_30"  # for continuing runs
  max_num_discs: 0
  # cem_init_std: 0.25 #real
  # cem_min_std: 0.12
  cem_init_std: 0.75
  cem_min_std: 0.1
  cem_pop: 384
  cem_iters: 3
  bootstrap_p: 0.75
  replay_recent_size: 550 # at 215 steps before 100
  mixed_replay_ratio: 0.2 # at 215 steps before 0.2
  angle_adjustment_deg: 1.0

cont_bandit_training:
  actor_lr: 0.0003
  critic_lr: 0.0003
  noise_std: 0.0

td3:
  policy_delay: 5
  tau: 0.005

sac:
  target_entropy: -2.0
  alpha_init: 0.1
  alpha_lr_mult: 1.0

ucb:
  ucb_beta: 1.8
  bootstrap_p: 0.7
  cem_init_std: 0.75
  cem_iters: 2
  cem_pop: 384
  cem_elite_frac: 0.16
  ucb_beta_final: 0.08
  cem_min_std: 0.1
  cem_warm_start: True

model:
  state_dim: 4
  action_dim: 2
  hidden_dim: 32
  speed_low: 1.0
  speed_high: 2.0
  angle_low: -20.0
  angle_high: 20.0

reward:
  distance_scale: 2.1
  in_hole_reward: 5.3
  w_distance: 0.9
  optimal_speed: 0.85
  dist_at_hole_scale: 6.0
  optimal_speed_scale: 1.5

